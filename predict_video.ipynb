{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from DatasetUtils import Dataset\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import imageio\n",
    "from IPython import display\n",
    "from urllib import request\n",
    "from tensorflow_docs.vis import embed\n",
    "import numpy as np\n",
    "\n",
    "data_path = '/home/kstef/dataset/'\n",
    "MODEL_TYPE = 'DeeplLabV3plus'\n",
    "MODEL_NAME = 'FocalHybrid_LeakyRelu_batch-3_Dropout-0.0_EfficientNetV2M'\n",
    "NUM_CLASSES = 20\n",
    "BACKBONE = 'EfficientNetV2M'\n",
    "BATCH_SIZE = 599\n",
    "subfolder = 'stuttgart_00'\n",
    "\n",
    "if BACKBONE == 'None':\n",
    "    PREPROCESSING = 'default'\n",
    "    BACKBONE = None\n",
    "elif 'ResNet' in BACKBONE:\n",
    "    PREPROCESSING = 'ResNet'\n",
    "elif 'EfficientNet' in BACKBONE:\n",
    "    PREPROCESSING = 'EfficientNet'\n",
    "elif 'EfficientNetV2' in BACKBONE:\n",
    "    PREPROCESSING = 'EfficientNetV2'\n",
    "else:\n",
    "    raise ValueError(f'Enter a valid Backbone name, {BACKBONE} is invalid.')\n",
    "\n",
    "MODEL_NAME = f'{MODEL_TYPE}/{MODEL_NAME}'\n",
    "MODELS_DIR = 'saved_models'\n",
    "pred_path = f'predictions/videoDemo/{MODEL_NAME}/frames'\n",
    "\n",
    "input_video_path = f'predictions/video/{MODEL_NAME}/{subfolder}/video/input.gif'\n",
    "pred_frame_path = f'predictions/video/{MODEL_NAME}/{subfolder}/frames'\n",
    "pred_video_path = f'predictions/video/{MODEL_NAME}/{subfolder}/video/prediction.gif'\n",
    "\n",
    "os.makedirs(pred_path, exist_ok=True)\n",
    "os.makedirs(pred_path, exist_ok=True)\n",
    "\n",
    "ds = Dataset(NUM_CLASSES, 'test', PREPROCESSING, shuffle=False, mode='video')\n",
    "ds = ds.create(data_path, subfolder, BATCH_SIZE, use_patches=False, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add val set filenames into a python list\n",
    "img_path_ds = tf.data.Dataset.list_files(f'{data_path}/demoVideo/{subfolder}/*.png', shuffle=False)\n",
    "img_name_list = []\n",
    "for img_path in img_path_ds:\n",
    "    split = tf.strings.split(img_path, sep='/').numpy()\n",
    "    img_name = split[-1]\n",
    "    img_name = img_name.decode()\n",
    "    img_name_list.append(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f'{MODELS_DIR}/{MODEL_NAME}', compile=False)\n",
    "\n",
    "eval_ids =   [7,8,11,12,13,17,19,20,21,22,23,24,25,26,27,28,31,32,33, 0] # MAP VOID CLASS TO 0 -> TOTAL BLACK \n",
    "train_ids =  [0,1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19]\n",
    "\n",
    "for dataset_elem, name in zip(ds, img_name_list):\n",
    "    input_image = dataset_elem[0]\n",
    "    # MAKE PREDICTION\n",
    "    prediction = model.predict_on_batch(input_image)\n",
    "    # PREDICTED LABEL IN GREYSCALE\n",
    "    prediction = tf.argmax(prediction, axis=-1)\n",
    "    prediction = tf.cast(prediction, tf.uint8)\n",
    "    prediction = tf.squeeze(prediction)\n",
    "    \n",
    "    if NUM_CLASSES == 20:\n",
    "        # map the classes back to the eval_ids\n",
    "        for train_id, eval_id in zip(reversed(train_ids), reversed(eval_ids)):        \n",
    "            prediction = tf.where(prediction==train_id, eval_id, prediction)\n",
    "            \n",
    "    prediction = tf.expand_dims(prediction, axis=-1)\n",
    "    # save predictions in 'predictions' folder\n",
    "    print('Saving prediciton for : ', name)\n",
    "    tf.keras.utils.save_img(f'{pred_path}/{name}', prediction, data_format='channels_last', scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gif(images, filename):\n",
    "  converted_images = images.astype(np.uint8)\n",
    "  imageio.mimsave(f'./{filename}', converted_images, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = next(iter(ds))[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_gif(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
