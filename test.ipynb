{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 12:40:48.761242: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.efficientnet import EfficientNetB4\n",
    "from SegmentationModels import DeepLabV3plus, Unet\n",
    "from DatasetUtils import Dataset\n",
    "from keras.applications import resnet, resnet_v2, densenet, efficientnet, efficientnet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 87., 161., 175.],\n",
       "        [134., 226., 126.],\n",
       "        [ 59.,  64., 149.],\n",
       "        [182., 145., 197.],\n",
       "        [ 83., 180.,   5.]],\n",
       "\n",
       "       [[ 70.,  38.,  60.],\n",
       "        [207., 232., 162.],\n",
       "        [ 30., 251., 184.],\n",
       "        [109., 197.,  68.],\n",
       "        [201., 147., 221.]],\n",
       "\n",
       "       [[ 18., 151., 116.],\n",
       "        [159.,  14.,  87.],\n",
       "        [104., 167.,  76.],\n",
       "        [188.,  96., 236.],\n",
       "        [118., 226.,  21.]],\n",
       "\n",
       "       [[186.,  82., 214.],\n",
       "        [246., 181., 247.],\n",
       "        [163., 145.,  98.],\n",
       "        [ 17.,  27.,  58.],\n",
       "        [ 21., 189.,  90.]],\n",
       "\n",
       "       [[ 37., 240., 223.],\n",
       "        [190., 191.,  47.],\n",
       "        [ 53., 117.,  57.],\n",
       "        [  6., 151., 179.],\n",
       "        [ 25.,   4., 146.]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.random.uniform((5, 5, 3), minval=0, maxval=255, dtype=tf.dtypes.int32)\n",
    "img = tf.cast(img, tf.dtypes.float32)\n",
    "img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  71.061     ,   44.221     ,  -36.68      ],\n",
       "        [  22.060997  ,  109.221     ,   10.32      ],\n",
       "        [  45.060997  ,  -52.779     ,  -64.68      ],\n",
       "        [  93.061     ,   28.221     ,   58.32      ],\n",
       "        [ -98.939     ,   63.221     ,  -40.68      ]],\n",
       "\n",
       "       [[ -43.939003  ,  -78.779     ,  -53.68      ],\n",
       "        [  58.060997  ,  115.221     ,   83.32      ],\n",
       "        [  80.061     ,  134.22101   ,  -93.68      ],\n",
       "        [ -35.939003  ,   80.221     ,  -14.68      ],\n",
       "        [ 117.061     ,   30.221     ,   77.32      ]],\n",
       "\n",
       "       [[  12.060997  ,   34.221     , -105.68      ],\n",
       "        [ -16.939003  , -102.779     ,   35.32      ],\n",
       "        [ -27.939003  ,   50.221     ,  -19.68      ],\n",
       "        [ 132.061     ,  -20.779     ,   64.32      ],\n",
       "        [ -82.939     ,  109.221     ,   -5.6800003 ]],\n",
       "\n",
       "       [[ 110.061     ,  -34.779     ,   62.32      ],\n",
       "        [ 143.061     ,   64.221     ,  122.32      ],\n",
       "        [  -5.939003  ,   28.221     ,   39.32      ],\n",
       "        [ -45.939003  ,  -89.779     , -106.68      ],\n",
       "        [ -13.939003  ,   72.221     , -102.68      ]],\n",
       "\n",
       "       [[ 119.061     ,  123.221     ,  -86.68      ],\n",
       "        [ -56.939003  ,   74.221     ,   66.32      ],\n",
       "        [ -46.939003  ,    0.22100067,  -70.68      ],\n",
       "        [  75.061     ,   34.221     , -117.68      ],\n",
       "        [  42.060997  , -112.779     ,  -98.68      ]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = resnet.preprocess_input(img)\n",
    "p_img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.31764704,  0.26274514,  0.37254906],\n",
       "        [ 0.05098045,  0.77254903, -0.01176471],\n",
       "        [-0.5372549 , -0.4980392 ,  0.1686275 ],\n",
       "        [ 0.427451  ,  0.13725495,  0.54509807],\n",
       "        [-0.3490196 ,  0.41176474, -0.9607843 ]],\n",
       "\n",
       "       [[-0.45098037, -0.7019608 , -0.5294118 ],\n",
       "        [ 0.62352943,  0.81960785,  0.27058828],\n",
       "        [-0.7647059 ,  0.96862745,  0.4431373 ],\n",
       "        [-0.14509803,  0.54509807, -0.46666664],\n",
       "        [ 0.5764706 ,  0.15294123,  0.73333335]],\n",
       "\n",
       "       [[-0.85882354,  0.18431377, -0.09019607],\n",
       "        [ 0.24705887, -0.8901961 , -0.31764704],\n",
       "        [-0.18431371,  0.30980396, -0.40392154],\n",
       "        [ 0.47450984, -0.24705881,  0.8509804 ],\n",
       "        [-0.0745098 ,  0.77254903, -0.8352941 ]],\n",
       "\n",
       "       [[ 0.45882356, -0.35686272,  0.6784314 ],\n",
       "        [ 0.92941177,  0.41960788,  0.9372549 ],\n",
       "        [ 0.27843142,  0.13725495, -0.23137254],\n",
       "        [-0.8666667 , -0.7882353 , -0.54509807],\n",
       "        [-0.8352941 ,  0.48235297, -0.29411763]],\n",
       "\n",
       "       [[-0.70980394,  0.88235295,  0.7490196 ],\n",
       "        [ 0.4901961 ,  0.49803925, -0.6313726 ],\n",
       "        [-0.58431375, -0.08235294, -0.5529412 ],\n",
       "        [-0.9529412 ,  0.18431377,  0.4039216 ],\n",
       "        [-0.8039216 , -0.96862745,  0.14509809]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = resnet_v2.preprocess_input(img)\n",
    "p_img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 87., 161., 175.],\n",
       "        [134., 226., 126.],\n",
       "        [ 59.,  64., 149.],\n",
       "        [182., 145., 197.],\n",
       "        [ 83., 180.,   5.]],\n",
       "\n",
       "       [[ 70.,  38.,  60.],\n",
       "        [207., 232., 162.],\n",
       "        [ 30., 251., 184.],\n",
       "        [109., 197.,  68.],\n",
       "        [201., 147., 221.]],\n",
       "\n",
       "       [[ 18., 151., 116.],\n",
       "        [159.,  14.,  87.],\n",
       "        [104., 167.,  76.],\n",
       "        [188.,  96., 236.],\n",
       "        [118., 226.,  21.]],\n",
       "\n",
       "       [[186.,  82., 214.],\n",
       "        [246., 181., 247.],\n",
       "        [163., 145.,  98.],\n",
       "        [ 17.,  27.,  58.],\n",
       "        [ 21., 189.,  90.]],\n",
       "\n",
       "       [[ 37., 240., 223.],\n",
       "        [190., 191.,  47.],\n",
       "        [ 53., 117.,  57.],\n",
       "        [  6., 151., 179.],\n",
       "        [ 25.,   4., 146.]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = efficientnet.preprocess_input(img)\n",
    "p_img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 87., 161., 175.],\n",
       "        [134., 226., 126.],\n",
       "        [ 59.,  64., 149.],\n",
       "        [182., 145., 197.],\n",
       "        [ 83., 180.,   5.]],\n",
       "\n",
       "       [[ 70.,  38.,  60.],\n",
       "        [207., 232., 162.],\n",
       "        [ 30., 251., 184.],\n",
       "        [109., 197.,  68.],\n",
       "        [201., 147., 221.]],\n",
       "\n",
       "       [[ 18., 151., 116.],\n",
       "        [159.,  14.,  87.],\n",
       "        [104., 167.,  76.],\n",
       "        [188.,  96., 236.],\n",
       "        [118., 226.,  21.]],\n",
       "\n",
       "       [[186.,  82., 214.],\n",
       "        [246., 181., 247.],\n",
       "        [163., 145.,  98.],\n",
       "        [ 17.,  27.,  58.],\n",
       "        [ 21., 189.,  90.]],\n",
       "\n",
       "       [[ 37., 240., 223.],\n",
       "        [190., 191.,  47.],\n",
       "        [ 53., 117.,  57.],\n",
       "        [  6., 151., 179.],\n",
       "        [ 25.,   4., 146.]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = efficientnet_v2.preprocess_input(img)\n",
    "p_img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.6280504 ,  0.78291327,  1.2456646 ],\n",
       "        [ 0.17681314,  1.9208683 ,  0.39163405],\n",
       "        [-1.1075436 , -0.91526604,  0.7925056 ],\n",
       "        [ 0.9988013 ,  0.50280124,  1.6291069 ],\n",
       "        [-0.69654936,  1.1155462 , -1.7172985 ]],\n",
       "\n",
       "       [[-0.91917115, -1.370448  , -0.7586928 ],\n",
       "        [ 1.42692   ,  2.0259104 ,  1.0190852 ],\n",
       "        [-1.6041614 ,  2.3585434 ,  1.4025275 ],\n",
       "        [-0.25130582,  1.4131653 , -0.6192592 ],\n",
       "        [ 1.3241715 ,  0.5378152 ,  2.0474076 ]],\n",
       "\n",
       "       [[-1.8096584 ,  0.6078432 ,  0.21734212],\n",
       "        [ 0.60493195, -1.7906162 , -0.28810447],\n",
       "        [-0.33692956,  0.88795525, -0.47982562],\n",
       "        [ 1.1015497 , -0.35504198,  2.3088455 ],\n",
       "        [-0.09718303,  1.9208683 , -1.4384314 ]],\n",
       "\n",
       "       [[ 1.0673003 , -0.60014   ,  1.9254032 ],\n",
       "        [ 2.0947855 ,  1.1330533 ,  2.5005665 ],\n",
       "        [ 0.673431  ,  0.50280124, -0.09638336],\n",
       "        [-1.8267832 , -1.5630252 , -0.79355115],\n",
       "        [-1.7582842 ,  1.2731093 , -0.23581691]],\n",
       "\n",
       "       [[-1.4842881 ,  2.1659663 ,  2.0822659 ],\n",
       "        [ 1.1357993 ,  1.3081232 , -0.9852723 ],\n",
       "        [-1.2102921 ,  0.01260505, -0.8109804 ],\n",
       "        [-2.0151556 ,  0.6078432 ,  1.3153814 ],\n",
       "        [-1.6897851 , -1.9656862 ,  0.74021804]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = densenet.preprocess_input(img)\n",
    "p_img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLabV3plus(input_shape=(1024,2048,3),\n",
    "                        filters=[16,32,64,128,256],\n",
    "                        num_classes=20,\n",
    "                        activation='leaky_relu',\n",
    "                        dropout_rate=0.0,\n",
    "                        backbone_name='EfficientNetB4',\n",
    "                        freeze_backbone=False,\n",
    "                        unfreeze_at='block6a_expand_activation'\n",
    "                        )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model,\n",
    "                          f\"{model.name}.png\",\n",
    "                          show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
