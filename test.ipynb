{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 18:07:42.314166: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.efficientnet import EfficientNetB4\n",
    "from SegmentationModels import DeepLabV3plus, Unet\n",
    "from DatasetUtils import Dataset\n",
    "from keras.applications import resnet, resnet_v2, densenet, efficientnet, efficientnet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[136., 250., 248.],\n",
       "        [ 67.,  20., 133.],\n",
       "        [ 68., 224., 173.],\n",
       "        [244.,  39., 180.],\n",
       "        [ 56., 220., 103.]],\n",
       "\n",
       "       [[136., 153., 157.],\n",
       "        [198., 196., 179.],\n",
       "        [ 41.,  66.,   8.],\n",
       "        [227., 175., 110.],\n",
       "        [ 82., 187.,  58.]],\n",
       "\n",
       "       [[102., 139.,  60.],\n",
       "        [200., 117.,  94.],\n",
       "        [ 71.,  29.,  83.],\n",
       "        [138., 150., 180.],\n",
       "        [152., 114., 132.]],\n",
       "\n",
       "       [[ 31.,  89.,  21.],\n",
       "        [153., 249., 235.],\n",
       "        [107., 114., 251.],\n",
       "        [203., 198., 216.],\n",
       "        [161., 157., 247.]],\n",
       "\n",
       "       [[ 14.,  35., 232.],\n",
       "        [ 63., 221.,  76.],\n",
       "        [123., 224., 248.],\n",
       "        [ 93., 182.,  46.],\n",
       "        [ 28.,  42., 147.]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.random.uniform((5, 5, 3), minval=0, maxval=255, dtype=tf.dtypes.int32)\n",
    "img = tf.cast(img, tf.dtypes.float32)\n",
    "img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 144.061     ,  133.22101   ,   12.32      ],\n",
       "        [  29.060997  ,  -96.779     ,  -56.68      ],\n",
       "        [  69.061     ,  107.221     ,  -55.68      ],\n",
       "        [  76.061     ,  -77.779     ,  120.32      ],\n",
       "        [  -0.939003  ,  103.221     ,  -67.68      ]],\n",
       "\n",
       "       [[  53.060997  ,   36.221     ,   12.32      ],\n",
       "        [  75.061     ,   79.221     ,   74.32      ],\n",
       "        [ -95.939     ,  -50.779     ,  -82.68      ],\n",
       "        [   6.060997  ,   58.221     ,  103.32      ],\n",
       "        [ -45.939003  ,   70.221     ,  -41.68      ]],\n",
       "\n",
       "       [[ -43.939003  ,   22.221     ,  -21.68      ],\n",
       "        [  -9.939003  ,    0.22100067,   76.32      ],\n",
       "        [ -20.939003  ,  -87.779     ,  -52.68      ],\n",
       "        [  76.061     ,   33.221     ,   14.32      ],\n",
       "        [  28.060997  ,   -2.7789993 ,   28.32      ]],\n",
       "\n",
       "       [[ -82.939     ,  -27.779     ,  -92.68      ],\n",
       "        [ 131.061     ,  132.22101   ,   29.32      ],\n",
       "        [ 147.061     ,   -2.7789993 ,  -16.68      ],\n",
       "        [ 112.061     ,   81.221     ,   79.32      ],\n",
       "        [ 143.061     ,   40.221     ,   37.32      ]],\n",
       "\n",
       "       [[ 128.061     ,  -81.779     , -109.68      ],\n",
       "        [ -27.939003  ,  104.221     ,  -60.68      ],\n",
       "        [ 144.061     ,  107.221     ,   -0.6800003 ],\n",
       "        [ -57.939003  ,   65.221     ,  -30.68      ],\n",
       "        [  43.060997  ,  -74.779     ,  -95.68      ]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = resnet.preprocess_input(img)\n",
    "p_img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.06666672,  0.9607843 ,  0.94509804],\n",
       "        [-0.47450978, -0.84313726,  0.04313731],\n",
       "        [-0.46666664,  0.75686276,  0.35686278],\n",
       "        [ 0.9137255 , -0.69411767,  0.41176474],\n",
       "        [-0.56078434,  0.7254902 , -0.19215685]],\n",
       "\n",
       "       [[ 0.06666672,  0.20000005,  0.2313726 ],\n",
       "        [ 0.5529412 ,  0.5372549 ,  0.4039216 ],\n",
       "        [-0.6784314 , -0.4823529 , -0.9372549 ],\n",
       "        [ 0.78039217,  0.37254906, -0.1372549 ],\n",
       "        [-0.35686272,  0.4666667 , -0.54509807]],\n",
       "\n",
       "       [[-0.19999999,  0.09019613, -0.5294118 ],\n",
       "        [ 0.5686275 , -0.08235294, -0.26274508],\n",
       "        [-0.44313723, -0.77254903, -0.3490196 ],\n",
       "        [ 0.082353  ,  0.17647064,  0.41176474],\n",
       "        [ 0.19215691, -0.10588235,  0.03529418]],\n",
       "\n",
       "       [[-0.75686276, -0.30196077, -0.8352941 ],\n",
       "        [ 0.20000005,  0.9529412 ,  0.84313726],\n",
       "        [-0.1607843 , -0.10588235,  0.96862745],\n",
       "        [ 0.5921569 ,  0.5529412 ,  0.69411767],\n",
       "        [ 0.26274514,  0.2313726 ,  0.9372549 ]],\n",
       "\n",
       "       [[-0.8901961 , -0.7254902 ,  0.81960785],\n",
       "        [-0.5058824 ,  0.73333335, -0.40392154],\n",
       "        [-0.03529412,  0.75686276,  0.94509804],\n",
       "        [-0.27058822,  0.427451  , -0.6392157 ],\n",
       "        [-0.78039217, -0.67058825,  0.15294123]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = resnet_v2.preprocess_input(img)\n",
    "p_img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[136., 250., 248.],\n",
       "        [ 67.,  20., 133.],\n",
       "        [ 68., 224., 173.],\n",
       "        [244.,  39., 180.],\n",
       "        [ 56., 220., 103.]],\n",
       "\n",
       "       [[136., 153., 157.],\n",
       "        [198., 196., 179.],\n",
       "        [ 41.,  66.,   8.],\n",
       "        [227., 175., 110.],\n",
       "        [ 82., 187.,  58.]],\n",
       "\n",
       "       [[102., 139.,  60.],\n",
       "        [200., 117.,  94.],\n",
       "        [ 71.,  29.,  83.],\n",
       "        [138., 150., 180.],\n",
       "        [152., 114., 132.]],\n",
       "\n",
       "       [[ 31.,  89.,  21.],\n",
       "        [153., 249., 235.],\n",
       "        [107., 114., 251.],\n",
       "        [203., 198., 216.],\n",
       "        [161., 157., 247.]],\n",
       "\n",
       "       [[ 14.,  35., 232.],\n",
       "        [ 63., 221.,  76.],\n",
       "        [123., 224., 248.],\n",
       "        [ 93., 182.,  46.],\n",
       "        [ 28.,  42., 147.]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = efficientnet.preprocess_input(img)\n",
    "p_img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[136., 250., 248.],\n",
       "        [ 67.,  20., 133.],\n",
       "        [ 68., 224., 173.],\n",
       "        [244.,  39., 180.],\n",
       "        [ 56., 220., 103.]],\n",
       "\n",
       "       [[136., 153., 157.],\n",
       "        [198., 196., 179.],\n",
       "        [ 41.,  66.,   8.],\n",
       "        [227., 175., 110.],\n",
       "        [ 82., 187.,  58.]],\n",
       "\n",
       "       [[102., 139.,  60.],\n",
       "        [200., 117.,  94.],\n",
       "        [ 71.,  29.,  83.],\n",
       "        [138., 150., 180.],\n",
       "        [152., 114., 132.]],\n",
       "\n",
       "       [[ 31.,  89.,  21.],\n",
       "        [153., 249., 235.],\n",
       "        [107., 114., 251.],\n",
       "        [203., 198., 216.],\n",
       "        [161., 157., 247.]],\n",
       "\n",
       "       [[ 14.,  35., 232.],\n",
       "        [ 63., 221.,  76.],\n",
       "        [123., 224., 248.],\n",
       "        [ 93., 182.,  46.],\n",
       "        [ 28.,  42., 147.]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = efficientnet_v2.preprocess_input(img)\n",
    "p_img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.21106265,  2.3410363 ,  2.5179958 ],\n",
       "        [-0.9705454 , -1.6855742 ,  0.51363856],\n",
       "        [-0.95342064,  1.8858544 ,  1.2108063 ],\n",
       "        [ 2.060536  , -1.352941  ,  1.3328106 ],\n",
       "        [-1.1589178 ,  1.8158263 , -0.0092374 ]],\n",
       "\n",
       "       [[ 0.21106265,  0.64285725,  0.9319392 ],\n",
       "        [ 1.2727973 ,  1.3956583 ,  1.3153814 ],\n",
       "        [-1.4157891 , -0.880252  , -1.6650109 ],\n",
       "        [ 1.7694151 ,  1.0280112 ,  0.11276696],\n",
       "        [-0.7136741 ,  1.2380953 , -0.79355115]],\n",
       "\n",
       "       [[-0.37117907,  0.3977592 , -0.7586928 ],\n",
       "        [ 1.3070468 ,  0.01260505, -0.16610013],\n",
       "        [-0.9020464 , -1.5280112 , -0.35782126],\n",
       "        [ 0.24531215,  0.5903362 ,  1.3328106 ],\n",
       "        [ 0.4850587 , -0.03991595,  0.49620935]],\n",
       "\n",
       "       [[-1.5870366 , -0.47759098, -1.4384314 ],\n",
       "        [ 0.50218344,  2.3235295 ,  2.2914162 ],\n",
       "        [-0.2855553 , -0.03991595,  2.5702832 ],\n",
       "        [ 1.3584211 ,  1.4306723 ,  1.9602616 ],\n",
       "        [ 0.63918144,  0.71288526,  2.5005665 ]],\n",
       "\n",
       "       [[-1.8781574 , -1.4229691 ,  2.2391288 ],\n",
       "        [-1.0390445 ,  1.8333333 , -0.47982562],\n",
       "        [-0.01155927,  1.8858544 ,  2.5179958 ],\n",
       "        [-0.5253019 ,  1.1505603 , -1.0027015 ],\n",
       "        [-1.6384109 , -1.30042   ,  0.7576472 ]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = densenet.preprocess_input(img)\n",
    "p_img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLabV3plus(input_shape=(1024,2048,3),\n",
    "                        filters=[16,32,64,128,256],\n",
    "                        num_classes=20,\n",
    "                        activation='leaky_relu',\n",
    "                        dropout_rate=0.0,\n",
    "                        backbone_name='EfficientNetB4',\n",
    "                        freeze_backbone=False,\n",
    "                        unfreeze_at='block6a_expand_activation'\n",
    "                        )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model,\n",
    "                          f\"{model.name}.png\",\n",
    "                          show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
